{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv(\"../experiments/results/result_rchar_1709153316/gpt-4-turbo_2/results.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"../experiments/results/result_rchar_1709153316/gpt-4-turbo_2/results_1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate Response - based on type of intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from rbias.constants import DATASETS, C_LADDERS, TASKS\n",
    "from rbias.query import analyze_result\n",
    "from rbias.process import sep_responses_based_on_inter\n",
    "from rbias.utils import get_taskwise_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = DATASETS\n",
    "c_rungs = C_LADDERS\n",
    "\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "#model_name = \"gpt-4-turbo\"\n",
    "#model_name = \"gpt-4\"\n",
    "#model_name = \"llama-2-7b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_folders = [f\"../experiments/results/result_rchar_1710342923/{model_name}_1/\",\n",
    "         f\"../experiments/results/result_cs_1710342947/{model_name}_1/\",\n",
    "         f\"../experiments/results/result_adv_1710343186/{model_name}_1/\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_responses_based_on_inter_task_0(response_folders, filters):\n",
    "    print(\"Separating responses according to obvious and non-obvious intervenstions...\")\n",
    "    for folder_path in response_folders:\n",
    "        print(\"result_folder: \", folder_path)\n",
    "        obv_res = []\n",
    "        non_obv_res = []\n",
    "        for rung in C_LADDERS:\n",
    "            for task_id in range(1):\n",
    "                exp_name = f\"{rung}_{task_id}\"\n",
    "                print(\"Exp name:\", exp_name)\n",
    "                sub_folder_path = os.path.join(folder_path, exp_name)\n",
    "                files = sorted(glob.glob(f\"{sub_folder_path}/*.csv\"))\n",
    "                for i, file in enumerate(files):\n",
    "                    df = pd.read_csv(file, index_col=0, sep = \"|\")\n",
    "                    # separate them into two dfs - one that change and the other that doesn't\n",
    "                    obv_inter, non_obv_inter = df.loc[filters[task_id][0]], df.loc[filters[task_id][1]]\n",
    "                    \n",
    "                    # store them in separate folders\n",
    "                    obv_path = os.path.join(sub_folder_path, \"obv_0\")\n",
    "                    if not os.path.isdir(obv_path):\n",
    "                        os.mkdir(obv_path)\n",
    "                    non_obv_path = os.path.join(sub_folder_path, \"non_obv_0\")\n",
    "                    if not os.path.isdir(non_obv_path):\n",
    "                        os.mkdir(non_obv_path)\n",
    "                    obv_inter.to_csv(os.path.join(obv_path, f\"response_{i}.csv\"), sep=\"|\")\n",
    "                    non_obv_inter.to_csv(os.path.join(non_obv_path, f\"response_{i}.csv\"), sep=\"|\")\n",
    "                    # generate separate results for obv and non_obv\n",
    "                    g_res = analyze_result(obv_inter)\n",
    "                    b_res = analyze_result(non_obv_inter)\n",
    "                    obv_res.append([exp_name, i, g_res[-1], *(g_res[:-1])])\n",
    "                    non_obv_res.append([exp_name, i, b_res[-1], *(b_res[:-1])])         \n",
    "        # store the result files\n",
    "        obv_res_df = pd.DataFrame(obv_res, columns = [\"exp_name\", \"trial\",\"size\", \"acc\", \"r_acc\", \"yes_acc\", \"no_acc\", \"f1_score\"])\n",
    "        non_obv_res_df = pd.DataFrame(non_obv_res, columns = [\"exp_name\", \"trial\", \"size\", \"acc\", \"r_acc\", \"yes_acc\", \"no_acc\", \"f1_score\"])\n",
    "        obv_res_df.to_csv(os.path.join(folder_path, \"obv_results_0.csv\"))\n",
    "        non_obv_res_df.to_csv(os.path.join(folder_path, \"non_obv_results_0.csv\"))\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] [0]\n",
      "[1 3 5] [0 2 4]\n",
      "[0 1 2 4 5 7 8] [3 6]\n",
      "[ 0  1  2  4  5  7  8  9 10 11 13 14 16 17 18 19 20 22 23 25 26] [ 3  6 12 15 21 24]\n",
      "[0 1 2 4 6] [3 5 7 8]\n",
      "[ 0  1  2  4  6  9 10 11 13 15 18 19 20 22 24] [ 3  5  7  8 12 14 16 17 21 23 25 26]\n",
      "Separating responses according to obvious and non-obvious intervenstions...\n",
      "result_folder:  ../experiments/results/result_rchar_1710342923/gpt-3.5-turbo_1/\n",
      "Exp name: obs_0\n",
      "Exp name: inter_0\n",
      "Exp name: sub_0\n",
      "result_folder:  ../experiments/results/result_cs_1710342947/gpt-3.5-turbo_1/\n",
      "Exp name: obs_0\n",
      "Exp name: inter_0\n",
      "Exp name: sub_0\n",
      "result_folder:  ../experiments/results/result_adv_1710343186/gpt-3.5-turbo_1/\n",
      "Exp name: obs_0\n",
      "Exp name: inter_0\n",
      "Exp name: sub_0\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "filters = get_taskwise_filters()\n",
    "sep_responses_based_on_inter(response_folders, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rbias.process import prep_taskwise_across_data_rungs, prep_taskwise_obv_non_obv_inter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Script to generate model wise diff comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"gpt-3.5-turbo\", \"gpt-4\", \"gpt-4-turbo\", \"llama-2-7b\"]\n",
    "res_file_template = [\"../experiments/results/result_rchar_1710342923/{model_name}_1/results.csv\",\n",
    "         \"../experiments/results/result_cs_1710342947/{model_name}_1/results.csv\",\n",
    "         \"../experiments/results/result_adv_1710343186/{model_name}_1/results.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_adv_diff = []\n",
    "cs_rchar_diff = []\n",
    "cs_adv_std = []\n",
    "cs_rchar_std = []\n",
    "for model_name in models:\n",
    "    result_files = [ f.format(model_name=model_name) for f in res_file_template ]\n",
    "    _, res_adata = prep_taskwise_across_data_rungs(result_files)\n",
    "    oi_avg = res_adata[:, :, 0, 0] - res_adata[:, :, 1, 0]\n",
    "    oi_std_max = np.maximum(res_adata[:, :, 0, 1], res_adata[:, :, 1, 1])\n",
    "    oi_std_sum = res_adata[:, :, 0, 1] + res_adata[:, :, 1, 1]\n",
    "    # append oi_diff of cs and adv.\n",
    "    cs_adv_diff.append([oi_avg[:, 1], oi_avg[:, 2]])\n",
    "    cs_rchar_diff.append([oi_avg[:, 1], oi_avg[:, 0]])\n",
    "    cs_adv_std.append([oi_std_sum[:, 1], oi_std_sum[:, 2]])\n",
    "    cs_rchar_std.append([oi_std_sum[:, 1], oi_std_sum[:, 0]])\n",
    "\n",
    "cs_adv_diff, cs_rchar_diff = np.array(cs_adv_diff), np.array(cs_rchar_diff)\n",
    "cs_adv_std, cs_rchar_std = np.array(cs_adv_std), np.array(cs_rchar_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.23333333,  0.15555556,  0.35555556],\n",
       "        [ 0.1       ,  0.23703704,  0.35925926]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.03333333,  0.07407407,  0.11111111],\n",
       "        [ 0.        ,  0.17777778,  0.15555556]],\n",
       "\n",
       "       [[ 0.13333333,  0.01851852,  0.28888889],\n",
       "        [ 0.23333333, -0.04444444,  0.12592593]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cs_adv_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.2       , 0.05443311, 0.04444444],\n",
       "        [0.13333333, 0.05023948, 0.0456465 ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.06666667, 0.03312693, 0.03312693],\n",
       "        [0.        , 0.09591002, 0.11626192]],\n",
       "\n",
       "       [[0.12472191, 0.12091846, 0.07216043],\n",
       "        [0.13333333, 0.09798882, 0.08406274]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " cs_adv_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13333333, -0.08148148, -0.0037037 ],\n",
       "       [ 0.        ,  0.        ,  0.        ],\n",
       "       [ 0.03333333, -0.1037037 , -0.04444444],\n",
       "       [-0.1       ,  0.06296296,  0.16296296]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cs_adv_diff[:, 0] - cs_adv_diff[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.23333333, 0.15555556, 0.35555556],\n",
       "        [0.16666667, 0.28888889, 0.40740741]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.0962963 ]],\n",
       "\n",
       "       [[0.03333333, 0.07407407, 0.11111111],\n",
       "        [0.03333333, 0.04444444, 0.07407407]],\n",
       "\n",
       "       [[0.13333333, 0.01851852, 0.28888889],\n",
       "        [0.36666667, 0.15555556, 0.34074074]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cs_rchar_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.2       , 0.05443311, 0.04444444],\n",
       "        [0.10540926, 0.04319224, 0.05737753]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.03777051]],\n",
       "\n",
       "       [[0.06666667, 0.03312693, 0.03312693],\n",
       "        [0.06666667, 0.03628874, 0.02342428]],\n",
       "\n",
       "       [[0.12472191, 0.12091846, 0.07216043],\n",
       "        [0.12472191, 0.05493253, 0.06907078]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " cs_rchar_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06666667, -0.13333333, -0.05185185],\n",
       "       [ 0.        ,  0.        , -0.0962963 ],\n",
       "       [ 0.        ,  0.02962963,  0.03703704],\n",
       "       [-0.23333333, -0.13703704, -0.05185185]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cs_rchar_diff[:, 0] - cs_rchar_diff[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Script to generate model wise diff comparisons for obvious interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rbias.process import prep_taskwise_obv_non_obv_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_taskwise_obv_non_obv_inter_0(res_folder_paths):\n",
    "    obv_data = []\n",
    "    for f, d in zip(res_folder_paths, DATASETS):\n",
    "        f = os.path.join(f, \"obv_results_0.csv\")\n",
    "        df = pd.read_csv(f, index_col=0)\n",
    "        arr = df[\"acc\"].to_numpy()\n",
    "        arr = arr.reshape((3, 1, -1))\n",
    "        avg, std = np.mean(arr, axis=2), np.std(arr, axis=2)\n",
    "        sub_arr = np.concatenate((avg[..., None], std[..., None]), axis = 2)\n",
    "        obv_data.append(sub_arr)\n",
    "\n",
    "    non_obv_data = []\n",
    "    for f, d in zip(res_folder_paths, DATASETS):\n",
    "        f = os.path.join(f, \"non_obv_results_0.csv\")\n",
    "        df = pd.read_csv(f, index_col=0)\n",
    "        arr = df[\"acc\"].to_numpy()\n",
    "        arr = arr.reshape((3, 1, -1))\n",
    "        avg, std = np.mean(arr, axis=2), np.std(arr, axis=2)\n",
    "        sub_arr = np.concatenate((avg[..., None], std[..., None]), axis = 2)\n",
    "        non_obv_data.append(sub_arr)\n",
    "    data = [obv_data, non_obv_data]\n",
    "    # (obv/non) - dataset - (inter/sub) - tasks - (avg/std) -> (inter/sub) - (tasks) - (dataset) - (obv/non) - (avg/std)\n",
    "    data = np.array(data).transpose([2, 3, 1, 0, 4])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"gpt-3.5-turbo\", \"gpt-4\", \"gpt-4-turbo\", \"llama-2-7b\"]\n",
    "res_file_template = [\"../experiments/results/result_rchar_1710342923/{model_name}_1/\",\n",
    "         \"../experiments/results/result_cs_1710342947/{model_name}_1/\",\n",
    "         \"../experiments/results/result_adv_1710343186/{model_name}_1/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo [[[[1.         0.        ]\n",
      "   [0.73333333 0.24944383]\n",
      "   [0.33333333 0.        ]]\n",
      "\n",
      "  [[1.         0.        ]\n",
      "   [0.8        0.26666667]\n",
      "   [0.33333333 0.        ]]\n",
      "\n",
      "  [[1.         0.        ]\n",
      "   [0.86666667 0.26666667]\n",
      "   [0.33333333 0.        ]]]]\n",
      "gpt-4 [[[[1.         0.        ]\n",
      "   [1.         0.        ]\n",
      "   [1.         0.        ]]\n",
      "\n",
      "  [[1.         0.        ]\n",
      "   [1.         0.        ]\n",
      "   [0.93333333 0.13333333]]\n",
      "\n",
      "  [[1.         0.        ]\n",
      "   [1.         0.        ]\n",
      "   [1.         0.        ]]]]\n",
      "gpt-4-turbo [[[[1.         0.        ]\n",
      "   [0.93333333 0.13333333]\n",
      "   [0.93333333 0.13333333]]\n",
      "\n",
      "  [[1.         0.        ]\n",
      "   [0.93333333 0.13333333]\n",
      "   [0.73333333 0.13333333]]\n",
      "\n",
      "  [[1.         0.        ]\n",
      "   [1.         0.        ]\n",
      "   [0.53333333 0.16329932]]]]\n",
      "llama-2-7b [[[[0.86666667 0.16329932]\n",
      "   [0.66666667 0.        ]\n",
      "   [0.66666667 0.        ]]\n",
      "\n",
      "  [[0.46666667 0.16329932]\n",
      "   [0.66666667 0.        ]\n",
      "   [0.66666667 0.        ]]\n",
      "\n",
      "  [[0.66666667 0.21081851]\n",
      "   [0.66666667 0.        ]\n",
      "   [0.66666667 0.        ]]]]\n"
     ]
    }
   ],
   "source": [
    "obv_cs_adv_diff = []\n",
    "obv_cs_rchar_diff = []\n",
    "obv_cs_adv_std = []\n",
    "obv_cs_rchar_std = []\n",
    "for model_name in models:\n",
    "    result_files = [ f.format(model_name=model_name) for f in res_file_template ]\n",
    "    inter_res = prep_taskwise_obv_non_obv_inter_0(result_files)\n",
    "    inter_res = inter_res[:, :, :, 0, :].transpose([1, 2, 0, 3])\n",
    "    print(model_name, inter_res)\n",
    "    oi_avg = inter_res[:, :, 0, 0] - inter_res[:, :, 1, 0]\n",
    "    oi_std_max = np.maximum(inter_res[:, :, 0, 1], inter_res[:, :, 1, 1])\n",
    "    oi_std_sum = inter_res[:, :, 0, 1] + inter_res[:, :, 1, 1]\n",
    "    obv_cs_adv_diff.append([oi_avg[:, 1], oi_avg[:, 2]])\n",
    "    obv_cs_rchar_diff.append([oi_avg[:, 1], oi_avg[:, 0]])\n",
    "    obv_cs_adv_std.append([oi_std_sum[:, 1], oi_std_sum[:, 2]])\n",
    "    obv_cs_rchar_std.append([oi_std_sum[:, 1], oi_std_sum[:, 0]])\n",
    "\n",
    "\n",
    "obv_cs_adv_diff, obv_cs_rchar_diff = np.array(obv_cs_adv_diff), np.array(obv_cs_rchar_diff)\n",
    "obv_cs_adv_std, obv_cs_rchar_std = np.array(obv_cs_adv_std), np.array(obv_cs_rchar_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.2       ],\n",
       "        [ 0.13333333]],\n",
       "\n",
       "       [[ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[ 0.06666667],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[-0.2       ],\n",
       "        [ 0.        ]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obv_cs_adv_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.26666667],\n",
       "        [0.26666667]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.13333333],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.16329932],\n",
       "        [0.21081851]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obv_cs_adv_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06666667],\n",
       "       [ 0.        ],\n",
       "       [ 0.06666667],\n",
       "       [-0.2       ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obv_cs_adv_diff[:, 0] - obv_cs_adv_diff[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.2       ],\n",
       "        [ 0.26666667]],\n",
       "\n",
       "       [[ 0.        ],\n",
       "        [ 0.        ]],\n",
       "\n",
       "       [[ 0.06666667],\n",
       "        [ 0.06666667]],\n",
       "\n",
       "       [[-0.2       ],\n",
       "        [ 0.2       ]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obv_cs_rchar_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.26666667],\n",
       "        [0.24944383]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.13333333],\n",
       "        [0.13333333]],\n",
       "\n",
       "       [[0.16329932],\n",
       "        [0.16329932]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obv_cs_rchar_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06666667],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [-0.4       ]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obv_cs_rchar_diff[:, 0] - obv_cs_rchar_diff[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script to generate retrieval performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"gpt-3.5-turbo\", \"gpt-4\", \"gpt-4-turbo\", \"llama-2-7b\"]\n",
    "res_file_template = [\"../experiments/results/result_rchar_1711052432/{model_name}_1/results.csv\",\n",
    "         \"../experiments/results/result_cs_1711052444/{model_name}_1/results.csv\",\n",
    "         \"../experiments/results/result_adv_1711052457/{model_name}_1/results.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(1.0, 0.0), (1.0, 0.0), (0.9888888888888889, 0.009938079899999069)], [(1.0, 0.0), (1.0, 0.0), (1.0, 0.0)], [(1.0, 0.0), (1.0, 0.0), (1.0, 0.0)], [(0.8666666666666666, 0.0557773351022717), (0.6333333333333333, 0.029814239699997195), (0.8555555555555555, 0.012171612389003673)]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Graph 1</th>\n",
       "      <th>Graph 2</th>\n",
       "      <th>Graph 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo</th>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(0.99, 0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4</th>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-2-7b</th>\n",
       "      <td>(0.87, 0.06)</td>\n",
       "      <td>(0.63, 0.03)</td>\n",
       "      <td>(0.86, 0.01)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Graph 1       Graph 2       Graph 3\n",
       "gpt-3.5-turbo    (1.0, 0.0)    (1.0, 0.0)  (0.99, 0.01)\n",
       "gpt-4            (1.0, 0.0)    (1.0, 0.0)    (1.0, 0.0)\n",
       "gpt-4-turbo      (1.0, 0.0)    (1.0, 0.0)    (1.0, 0.0)\n",
       "llama-2-7b     (0.87, 0.06)  (0.63, 0.03)  (0.86, 0.01)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = []\n",
    "for model_name in models:\n",
    "    res_files = [ f.format(model_name=model_name) for f in res_file_template[:1] ]\n",
    "    df = pd.read_csv(res_files[0], index_col=0)\n",
    "    obs_perf = df.iloc[list(range(15))][\"acc\"].to_numpy().reshape(3, -1)\n",
    "    m, sterr = obs_perf.mean(axis=1), obs_perf.std(axis=1)/np.sqrt(5)\n",
    "    res.append(list(zip(m.tolist(), sterr.tolist())))\n",
    "    # res.append((model_name, m, sterr))\n",
    "print(res)\n",
    "res_df = pd.DataFrame(res, columns = [ \"Graph 1\", \"Graph 2\", \"Graph 3\"], index = models).map(lambda x: (round(x[0], 2), round(x[1], 2)))\n",
    "res_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$100.0 \\pm 0.0$ & $100.0 \\pm 0.0$ & $99.0 \\pm 1.0$ \\\\\n",
      "$100.0 \\pm 0.0$ & $100.0 \\pm 0.0$ & $100.0 \\pm 0.0$ \\\\\n",
      "$100.0 \\pm 0.0$ & $100.0 \\pm 0.0$ & $100.0 \\pm 0.0$ \\\\\n",
      "$87.0 \\pm 6.0$ & $63.0 \\pm 3.0$ & $86.0 \\pm 1.0$ \\\\\n"
     ]
    }
   ],
   "source": [
    "for row in res_df.iterrows():\n",
    "    print(\" & \".join(map(lambda x: f\"${x[0]} \\\\pm {x[1]}$\", row[1].values)) + \" \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
